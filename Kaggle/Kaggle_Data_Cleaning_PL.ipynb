{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "Poniższy notebook sporządzono na podstawie kursu dostępnego pod adresem https://www.kaggle.com/learn/data-cleaning\n",
    "\n",
    "**Zawiera on jedynie wybrane zagadnienia!**\n",
    "\n",
    "Agenda:\n",
    "1. **Handling Missing Values**\n",
    "2. **Scaling and Normalization**\n",
    "3. **Parsing Dates**\n",
    "4. Character Encodings (brak poniżej, więcej: https://www.kaggle.com/alexisbcook/character-encodings)\n",
    "5. **Inconsistent Data Entry**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) HANDLING MISSING VALUES\n",
    "\n",
    "### Rzucenie okiem na dane\n",
    "\n",
    "Pierwszą czynnością pracy z danymi jest ich wczytanie i wstępna (wizualna) analiza:\n",
    "- dataset.head()\n",
    "- dataset.describe()\n",
    "\n",
    "Warto również zapoznać się z **dokumentacją** zbioru danych, jeśli korzystamy ze zbioru utworzonego przez kogoś innego (np. z kaggle.com).\n",
    "\n",
    "### Określenie liczby brakujących danych (NaN, None)\n",
    "\n",
    "Dobrą praktyką jest sprawdzenie czy nasz zbiór danych posiada jakieś braki:\n",
    "\n",
    "<img src=\"Images/img_22.jpg\">\n",
    "\n",
    "Już po pierwszych 10 kolumnach widać, że mamy sporo brakujących wartości. Aby uchwycić skalę problemu najlepiej jest określić **procent** brakujących wartości w naszym zbiorze danych.\n",
    "\n",
    "<img src=\"Images/img_23.jpg\">\n",
    "\n",
    "Widać wyraźnie, że blisko 1/4 komórek jest pusta (NaN lub None).\n",
    "\n",
    "### Określenie skąd się biorą braki danych\n",
    "\n",
    "_\"Look at your data and try to figure out why it is the way it is and how that will affect your analysis\"_\n",
    "\n",
    "Aby sprawnie radzić sobie z brakami danych potrzebne jest doświadczenie (i intuicja!). Dobrym pytaniem, które warto sobie postawić próbując znaleźć odpowiedź na pytanie skąd biorą się brakujące wartości jest: \n",
    "\n",
    "**Czy konkretny brak danych wynika z faktu, że dana wartość nie została zarejestrowana, czy ponieważ w ogóle nie istnieje?**\n",
    "\n",
    "Jeśli mamy do czynienia z brakiem, który wynika z faktu, że dana wartość nie istnieje (np. wzrost najstarszego dziecka kogoś, kto w ogóle nie ma dzieci), to nie ma sensu szukać sposobu na uzupełnienie takiego braku - najlepiej pozostawić wartość NaN.\n",
    "\n",
    "Jeśli jednak brak wynika z tego, że dana wartość nie została zarejestrowana (ale prawdopodobnie może istnieć), wtedy można pokusić się o \"przewidzenie\" brakującej wartości w oparciu o istniejące wartości danej kolumny (cechy) - proces ten nosi nazwę **imputacji (ang. imputation)**.\n",
    "\n",
    "Przykładowo, dla pierwszych 10 kolumn jak wyżej, kolumna _time_ określa liczbę sekund jakie pozostały do końca meczu w momencie wykonania akcji. Wynika stąd, że wszystkie braki w kolumnie _time_ wynikają z tego, że po prostu ich nie zarejestrowano! Stąd, sensowne wydaje się podjąć próbę ich zastąpienia zamiast pozostawić jako NA.\n",
    "\n",
    "Z drugiej strony kolumna _PenalizedTeam_ również zawiera wiele braków, ale w tym przypadku biorą się one z faktu, że po prostu żadna z drużym nie została w danej akcji ukarana (nie było przewinienia), dlatego szukanie \"na siłę\" wartości (drużyny) do wstawienia jest bez sensu i należy pozostawić NA lub ewentualnie wstawić coś a'la \"brak\".\n",
    "\n",
    "**WNIOSEK:**\n",
    "\n",
    "Warto skupić się na każdej kolumnie z osobna i dość szczegółowo przeanalizować w jaki sposób najlepiej poradzić sobie z brakującymi wartościami.\n",
    "\n",
    "### Usuwanie brakujących wartości\n",
    "\n",
    "Jedną z najszybszych (ale niekoniecznie najlepszych) metod radzenia sobie z brakami danych jest usunięcie wierszy (lub nawet kolumn, jeśli braków jest ponad 50% w danej kolumnie) zawierających braki.\n",
    "\n",
    "<img src=\"Images/img_24.jpg\">\n",
    "\n",
    "Jak widać, użycie metody \"dropna\" może spowodować usunięcie wszystkich wierszy, jeśli każdy z nich zawierał przynajmniej jedną brakującą wartość. W takiej sytuacji lepszym rozwiązaniem może być usunięcie kolumn, które posiadają braki:\n",
    "\n",
    "<img src=\"Images/img_25.jpg\">\n",
    "\n",
    "<img src=\"Images/img_26.jpg\">\n",
    "\n",
    "Metoda polegająca na usunięciu kolumn również nie jest najlepsza, bo doprowadziła do ponad 2-krotnego zmniejszenia naszego zbioru danych...\n",
    "\n",
    "**WSKAZÓWKA:**\n",
    "\n",
    "Metoda całkowitego usuwania brakujących wartości nie jest rekomendowana w pracy przy ważnych komercyjnych projektach!\n",
    "\n",
    "### Automatyczne uzupełnianie brakujących wartości\n",
    "\n",
    "Inną opcji radzenia sobie z brakami danych jest ich uzupełnienie.\n",
    "\n",
    "(Poniższy przykład celowo dotyczy wycinka całego zbioru danych, aby pokazać o co chodzi.)\n",
    "\n",
    "<img src=\"Images/img_27.jpg\">\n",
    "\n",
    "Używając modułu Pandas mamy możliwość skorzystania z metody _fillna(n)_ , która zastępuje wszystkie braki danych NAN występujące w DataFramie wskazaną wartością _n_ .\n",
    "\n",
    "<img src=\"Images/img_28.jpg\">\n",
    "\n",
    "Innym, nieco sprytniejszym, sposobem jest zastąpienie braku wartością, która występuje bezpośrednio po nim (po braku) w tej samej kolumnie. Takie działanie ma sens w przypadku zbiorów, w których obserwacje mają jakiś logiczny porządek.\n",
    "\n",
    "<img src=\"Images/img_29.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) SCALING AND NORMALIZATION\n",
    "\n",
    "### Skalowanie vs. Normalizacja: Jaka jest różnica?\n",
    "\n",
    "Jeden z powodów, dlaczego łatwo się pogubić poruszając temat skalowania i normalizacji jest fakt, że oba te terminy często są stosowane zamiennie. Dzieje się tak, ponieważ oba procesy są bardzo podobne! Zarówno jeden, jak i drugi polega na transformacji danych liczbowych (zmiennych numerycznych) w taki sposób, aby dane te po przekształceniu miały pewne, określone (i pomocne z punktu widzenia modelu) właściwości. Różnica pomiędzy skalowaniem i normalizacją polega na tym, że:\n",
    "* podczas **skalowania** zmieniamy _zakres (range)_ danych\n",
    "* podczas **normalizacji** zmieniamy _kształt rozkładu (shape of the distribution)_ danych\n",
    "\n",
    "**Moduły dla skalowania i normalizacji:**\n",
    "\n",
    "<img src=\"Images/img_30a.jpg\">\n",
    "\n",
    "### Skalowanie\n",
    "\n",
    "Polega na modyfikacji naszych danych w taki sposób, że mieszczą się one w określonym zakresie, np 0-100 lub 0-1. Skalowanie jest stosowane, gdy używamy algorytmów opartych na miarach odległości między punktami danych, np. **SVM (Support Vector Machines)** lub **K-NN (K-Nearest Neighbours)**. W tych algorytmach zmiana o \"1\" w dowolnej funkcji numerycznej ma taką samą wagę.\n",
    "\n",
    "Przykładowo, nasz zbiór danych może zawierać ceny niektórych produktów w jenach i dolarach. Jeden dolar to około 100 jenów, ale jeśli nie przeskalujemy cen w naszym zbiorze, to algorytmy takie jak SVM czy KNN potraktują różnicę w cenie 1 jena tak samo ważną, jak różnicę 1 dolara!!! A co jeśli mamy wzrost i wagę? Tutaj akurat nie da się jasno określić ile kg powinno równać się jednemu centymetrowi, dlatego skalowanie nie ma zastosowania.\n",
    "\n",
    "Skalowanie umożliwa zatem porównywanie różnych zmiennych \"na równych zasadach\".\n",
    "\n",
    "<img src=\"Images/img_31.jpg\">\n",
    "\n",
    "Zauważmy, że _kształt_ danych na powyższym przykładzie nie zmienił się. Zmianie uległ natomiast zakres wartości (oś pozioma) z 0-8 na 0-1.\n",
    "\n",
    "### Normalizacja\n",
    "\n",
    "W porównaniu do skalowania, normalizacja jest bardziej radykalną transformacją danych. Celem normalizacji jest zmiana obserwacji w ten sposób, aby dało się je opisać za pomocą **rozkładu normalnego**.\n",
    "\n",
    "Ogólnie rzecz biorąc, normalizacje stosuje się, gdy zamierzamy używać modelu uczenia maszynowego lub techniki statystycznej, która zakłada, że dane posiadają rozkład normalny. Przykładami takich technik są **analiza wariancji (ANOVA)** , **regresja liniowa** , **liniowa analiza dyskryminacyjna (LDA)** , **naiwny klasyfikator Bayesowski** oraz (w ciemno) metody zawierające **\"Gaussian\"** w nazwie.\n",
    "\n",
    "Jedną z metod normalizacji jest metoda **Box'a-Cox'a**:\n",
    "\n",
    "<img src=\"Images/img_32.jpg\">\n",
    "\n",
    "Zauważmy, że _kształt_ danych na powyższym przykładzie uległ zmianie. Przed normalizacją był niemal w kształcie litery \"L\", zaś po normalizacji przypomina rozkład normalny (krzywa dzwonowa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) PARSING DATES\n",
    "\n",
    "Poniżej, na przykładowym zbiorze danych omówiono sposoby radzenia sobie z niewłaściwymi formatami dat i ich zamianą na format rozpoznawany przez Pythona.\n",
    "\n",
    "Początkowy format kolumny 'date':\n",
    "\n",
    "<img src=\"Images/img_33.jpg\">\n",
    "\n",
    "Jak widać kolumna 'date' ma typ 'object', a więcj Python traktuje ją jak string.\n",
    "\n",
    "### Konwersja na typ _datetime_\n",
    "\n",
    "Proces konwersji na typ _datetime_ nosi nazwę **parsing dates** (parsowanie dat), ponieważ bierzemy string i każdy jego element identyfikujemy jako konkretną część daty. Przede wszystkim polega to na zidentyfikowaniu jaką część daty reprezentują poszczególne lementu stringa i czym są oddzielone od siebie. Najpowszechniejsze: %d - day, %m - month, %y - two-digit year, %Y - four-digit year). Przykłady:\n",
    "\n",
    "- 1/17/07 ma format: %m/%d/%y\n",
    "- 17-1-2007 ma format: %d-%m-%Y\n",
    "\n",
    "Nasz przykład ewidentnie pasuje do formatu \"%m/%d/%y\". \n",
    "\n",
    "<img src=\"Images/img_34.jpg\">\n",
    "\n",
    "Nasza nowopowstała kolumna 'date_parsed' posiada typ \"datetime64\", który posiada porządek zapisu \"year-month-day\":\n",
    "\n",
    "<img src=\"Images/img_35.jpg\">\n",
    "\n",
    "**Co w sytuacji, gdy otrzymamy błąd \"multiple date formats\"?**\n",
    "\n",
    "Może się zdarzyć, że kolumna, którą chcemy \"sparsować\" na format \"datetime64\" zawiera stringi reprezentujące daty w kilku różnych formatach. W takiej sytuacji możemy użyć _pandas_ z, aby ten spróbował sobie z tym poradzić poprzez funkcję _\"infer_datetime_format = True\"_ :\n",
    "\n",
    "<img src=\"Images/img_36.jpg\">\n",
    "\n",
    "**Dlaczego nie używać _\"infer_datetime_format = True\"_ za każdym razem?**\n",
    "\n",
    "Dwa powody:\n",
    "- nie zawsze pandas będzie w stanie poradzić sobie z rozszyfrowaniem formatu\n",
    "- metoda _\"infer...\"_ jest dużo wolniejsza niż dokładne wskazanie formatu przez nas\n",
    "\n",
    "### Wyciąganie elementów z daty\n",
    "\n",
    "Gdy mamy już datę w formacie \"datetime\" możemy wyciągać z niej interesujące nas elementy. Poniżej np. wyciągniemy dzień miesiąca:\n",
    "\n",
    "<img src=\"Images/img_37.jpg\">\n",
    "\n",
    "### Sprawdzenie czy \"sparsowaliśmy\" daty poprawnie\n",
    "\n",
    "Jednym z najczęstszych błędów związanych z zamianą stringów na daty jest pomieszanie miesięcy i dni, ponieważ funkcja _\"to_datetime()\"_ w żaden sposób nie informuje nas czy np. dany miesiąc nie ma wartości >12, albo czy wartości dla dnia miesiąca nie kończą się na 12. Najlepszym sposobem na sprawdzenie czy wszystki przebiegło pomyślnie jest zwizualizowanie, np. w formie histogramu, wartości dla dni i sprawdzenie czy zawierają się w przedziale 1-31.\n",
    "\n",
    "<img src=\"Images/img_38.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) INCONSISTENT DATA ENTRY\n",
    "\n",
    "**Przydatne moduły:**\n",
    "\n",
    "<img src=\"Images/img_39.jpg\">\n",
    "\n",
    "### Zajrzenie w dane\n",
    "\n",
    "<img src=\"Images/img_40.jpg\">\n",
    "\n",
    "Skupimy się na kolumnie \"Country\" i spróbujemy upewnić się, że nie zawiera ona żadnych niespójności, jeśli chodzi o wartości, które zawiera.\n",
    "\n",
    "<img src=\"Images/img_41.jpg\">\n",
    "\n",
    "Łatwo zauważyć, że istnieją niespójności w kolumnie \"Country\", np. ' Germany' i 'germany'. \n",
    "\n",
    "### Wielkość liter i białe znaki\n",
    "\n",
    "Pierwszą rzeczą, którą warto zrobić jest zamiana wszystkich wartości na _lowercase_ (w razie czego łatwo ten proces odwrócić) oraz pozbyć się białych znaków na początku i końcu każdej wartości. \n",
    "\n",
    "**Wskazówka**: Niespójności w danych tekstowych związane z wielkością liter lub występowaniem białych znaków na początku/końcu wartości są bardzo powszechne i pozbywając się ich można rozwiązać około 80% problemów dot. niespójnych danych\n",
    "\n",
    "<img src=\"Images/img_42.jpg\">\n",
    "\n",
    "### Moduł _fuzzywuzzy_\n",
    "\n",
    "Sprawdźmy czy występują jeszcze jakieś niespójności w kolumnie \"Country\" oprócz powyższych:\n",
    "\n",
    "<img src=\"Images/img_43.jpg\">\n",
    "\n",
    "Widać, że występują jeszcze inne niespójności, np. 'south korea' i 'southkorea' czy 'usa' i 'usofa'.\n",
    "\n",
    "Można próbować rozwiązać je ręcznie, ale jest to czasochłonne, dlatego skorzystamy z modułu **_fuzzywuzzy_** . Pozwala on zidentyfikować, które stringi są do siebie najbardziej podobne.\n",
    "\n",
    "**Fuzzy matching:** Proces polegający na automatycznym znajdowaniu stringów, które są najbardziej podobne do wskazanego łańcucha znaków (target string). Podobieństwo w tym przydku jest rozumiane następująco: jeden string jest tym bardziej podobny do drugiego, im mniej znaków trzeba zamienić, aby oba były identyczne. Przykładowo, \"apple\" i \"snapple\" - dwie zmiany (dodanie \"s\" i \"n\" do \"apple\", aby otrzymać \"snapple\"). _Fuzzy matching_ , to nie zawsze jest to użyteczna metoda, ale ogólnie pomocna.\n",
    "\n",
    "_Fuzzywuzzy_ zwraca stosunek (ratio) dwóch stringów. Im stosunek bliższy 100, tym mniejsza różnica między dwoma stringami. W powyższym przykładzie otrzymamy dziesięć stringów z listy miast, które mają najmniejszy dystans do \"south korea\":\n",
    "\n",
    "<img src=\"Images/img_44.jpg\">\n",
    "\n",
    "Jak widać najbardziej podobnym stringiem do \"south korea\" jest \"southkorea\", dlatego zastąpimy wszystkie wiersze kolumny \"Country\", gdzie stosunek podobieństwa do \"south korea\" (ratio) jest > 47. Do tego celu stworzono poniższą funkcję:\n",
    "\n",
    "<img src=\"Images/img_45.jpg\">\n",
    "\n",
    "Zamiana:\n",
    "\n",
    "<img src=\"Images/img_46.jpg\">\n",
    "\n",
    "Sprawdzenie:\n",
    "\n",
    "<img src=\"Images/img_47.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
