{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Poniższy notebook sporządzono na podstawie kursu dostępnego pod adresem https://www.kaggle.com/learn/feature-engineering. \n",
    "\n",
    "**Zawiera on jedynie wybrane zagadnienia!**\n",
    "\n",
    "Agenda:\n",
    "1. Baseline Model (brak poniżej, więcej: https://www.kaggle.com/matleonard/baseline-model)\n",
    "2. **Categorical Encodings**\n",
    "3. **Feature Generation**\n",
    "4. **Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) CATEGORICAL ENCODINGS\n",
    "Rozwinięcie wiadomości z rozdziału 3. Categorical Variables z kursu \"Intermediate Machine Learning\". Oprócz zawartych w nim metod radzenia sobie ze zmiennymi kategorycznymi istnieją jeszcze inne, np.\n",
    "\n",
    "- count encoding\n",
    "- target encoding\n",
    "- CatBoost encoding\n",
    "\n",
    "#### Count Encoding\n",
    "\n",
    "Polega na zastąpieniu każdej z wartości kategorycznych liczbą jej wystąpień w zbiorze danych. Przykładowo, jeśli wartość \"GB\" pojawia się w zbiorze 10 razy, to każde wystąpienie \"GB\" zostanie zastąpione liczbą 10. \n",
    "\n",
    "Chcąc skorzystać z tej metody należy użyć biblioteki 'category_encoders' oraz metody 'CountEncoder', która działa z metodami '.fit' oraz '.transform' pochodzącymi z pakietu Scikit-Learn.\n",
    "\n",
    "<img src=\"Images/img_10.jpg\">\n",
    "\n",
    "#### Target Encoding\n",
    "\n",
    "Polega na zastąpieniu wartości kategorycznych średnią wartością obliczoną na podstawie poszczególnych wartości zmiennej przewidywanej (target) dla danej wartości zmiennej kategorycznej (inaczej, grupuje unikalne wartości zmiennej kategorycznej, oblicza dla każdej grupy średnią wartość targetu i wstawia w każdy wiersz należący do tej grupy).\n",
    "\n",
    "Ta technika wykorzystuje zmienną docelową (target) do utworzenia nowej cechy (która ma zastąpić cechę \"kategorczną\"), dlatego wykorzystanie tej nowej cechy do treningu lub walidacji modelu byłoby w pewnym sensie **wyciekiem danych** (data leakage). Należy zatem zastosować \"target encodings\" jedynie dla zbioru treningowego.\n",
    "\n",
    "Chcąc skorzystać z tej metody należy użyć biblioteki 'category_encoders' oraz metody 'TargetEncoder', która działa z metodami '.fit' oraz '.transform' pochodzącymi z pakietu Scikit-Learn.\n",
    "\n",
    "<img src=\"Images/img_11.jpg\">\n",
    "\n",
    "#### CatBoost Encoding\n",
    "\n",
    "Metoda ta jest podobna do \"Target Encoding\", ponieważ również opiera się na wartościach zmiennej przewidywanej (target), jednakże stosując \"CatBoost Encoding\" wartość prawdopodobieństwa jest obliczana jedynie na podstawie wierszy poprzedzających wiersz, dla którego chcemy obliczyć nową wartość zmiennej kategorycznej.\n",
    "\n",
    "<img src=\"Images/img_12.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) FEATURE GENERATION\n",
    "Technika polegająca na ulepszaniu modelu poprzez tworzenie nowych cech na podstawie surowego zbioru danych. Przykładowo, pracując na zbiorze danych możemy utworzyć nowe kolumny (cechy), zawierające np. \n",
    "- liczbę projektów w poszczególnych tygodniach (cecha zostanie utworzona w oparciu o kolumnę zaw. daty)\n",
    "- czas trwania każdego projektu\n",
    "- czas jaki upłynął od ukończenia projektu\n",
    "- zmodyfikowane wartości liczbowe (np. jeśli ich wartości mają b.duży zakres - patrz: przykład poniżej)\n",
    "\n",
    "Przykład:\n",
    "**Modyfikacja wartości liczbowych**\n",
    "Dla przykładowego zbioru danych zakres wartości w kolumnie \"Goal\" mówi nam, że większość projektów ma \"cele\" niższe niż 5000 USD. Istnieje jednak sporo przypadków sięgających 100 000 USD. Nasz model może pracować lepiej, gdy cechy mają \"ujednolicone\" wartości (normally distributed) więc może pomocna może być ich modyfikacja. Najpowszechniejszymi przykładami przekształceń wartości numerycznych są \"pierwiastek kwadratowy (square root) oraz \"algorytm naturalny\" (natural algorithm). Te przekształcenia mogą również być pomocne w przypadku występowania wartości odstających (outliers)\n",
    "\n",
    "Rozkład wartości cechy \"Goal\" przez modyfikacją:\n",
    "\n",
    "<img src=\"Images/img_13.jpg\">\n",
    "\n",
    "Przekształcenie z użyciem \"square root\":\n",
    "\n",
    "<img src=\"Images/img_14.jpg\">\n",
    "\n",
    "Przekształcenie z użyciem \"natural algorithm (log)\":\n",
    "\n",
    "<img src=\"Images/img_15.jpg\">\n",
    "\n",
    "UWAGA!\n",
    "\n",
    "Transformacja z użyciem logarytmu naturalnego (log) jest bezużyteczna dla modeli opartych o Drzewa Decyzyjne. Będzie ona za to pomocna w przypadku modeli liniowych i sieci neuronowych!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) FEATURE SELECTION\n",
    "\n",
    "Podczas pracy z danymi bardzo często będziemy mieli do czynienia z sytuacją, że mamy setki (a nawet więcej) cech (kolumn) pochodzących z oryginalnego zbioru danych lub utworzonych przez nas w procesie obróbki (Encodings, Feature Generation etc.). Prowadzi to do dwóch podstawowych problemót:\n",
    "1. Im więcej cech (kolumn), tym większe ryzyko przetrenowania modelu.\n",
    "2. Im więcej cech (kolumn), tym więcej czasu potrzeba na wytrenowanie modelu i dostrojenie hiperparametrów.\n",
    "\n",
    "W związku z powyższym konieczne jest wybranie najlepszych cech dla naszego modelu (cech, które zawierają najwięcej informacji z punktu widzenia naszego modelu i prognoz, które chcemy przeprowadzać)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metody wyboru cech\n",
    "\n",
    "#### Wybór funkcji jednej zmiennej (ang. Univariate Feature Selection)\n",
    "\n",
    "Najprostsze i najszybsze metody oparta są na jednowymiarowych testach statystycznych (ang. univariate statistical tests). Polega to na tym, że dla każdej cechy mierzymy w jakim stopniu zmienna przewidywana (target) zależy od tej cechy - do pomiaru tej zależności może posłużyć np. **test chi-kwadrat χ2** lub **analiza wariancji (ANOVA, ang. analysis of variance)**.\n",
    "\n",
    "W pakiecie Scikit-Learn do wyboru cech służy moduł **\"feature_selection\"**. Funkcja **SelectKBest** zwraca _K_ najlepszych cech z punktu widzenia funkcji oceniającej, którą może być jedna z trzech funkcji:\n",
    "- chi-kwadrat χ2, \n",
    "- ANOVA (F-value) \n",
    "- wzajemny wynik informacyjny (ang. mutual information score).\n",
    "\n",
    "F-value mierzy liniową zależność między cechą, a zmienną przewidywaną (targetem). Oznacza to, że wynik może wystarczająco nie uwzględniać relacji pomiędzy badaną cechą a targetem jeśli jest ona nieliniowa (patrz przykład zmiennych zależnych, gdzie Y to wart. bezwzlg. z X - liniowej zależności nie ma, ale ogólnie zależność istnieje i jest nią właśnie wart. bezwzgl.).\n",
    "\n",
    "Wzajemny wynik informacyjny (ang. mutual information score) jest nieparametryczny więc może uwzględniać zależność nieliniową!\n",
    "\n",
    "Stosując metodę SelectKBest definiujemy liczbę _K_ cech, które chcemy zachować jako wynik zastosowania jednej z funkcji oceniających. Używając _.fit_transform(features, target)_ otrzymujemy tablicę zawierającą tylko wybrane (poprzez SelectKBest) cechy.\n",
    "\n",
    "**PRZYKŁAD**\n",
    "\n",
    "<img src=\"Images/img_16.jpg\">\n",
    "\n",
    "Niestety, w powyższym przekształceniu zrobiliśmy błąd - obliczyliśmy test statystyczny (F-value = f_classif) używając całego zbioru danych. Oznacza to, że informacje zawarte w zbiorze testowym i walidacyjnym mogą wpływać na cechy, które chcemy ustatecznie zachować do trenowania modelu (jest to źródło _wycieku danych_ ). W celu naprawy tego błędu należy dokonać wyboru cech jedynie na zbiorze treningowym (odpalić \"SelectKBest\" na zbiorze treningowym a nie na całym zbiorze danych!)\n",
    "\n",
    "<img src=\"Images/img_17.jpg\">\n",
    "\n",
    "Należy zwrócić uwagę, że obecnie otrzymaliśmy tablicę zawierającą same wartości wyboranych cech jedynie dla zbioru treningowego (zastosowaliśmy \"SelectKBest\" jedynie na zbiorze treningowym a więc zbiór walidacyjny i testowy mają nadal ten sam, początkowy, zbiór cech). Aby usunąć zbędne cechy ze zbioru walidacyjnego i testowego musimy dowiedzieć się, które kolumny zostały zachowane jako wynik \"SeleckKBest\". W tym celu można użyć metody _.inverse_transform_ , która zwraca tablicę o kształcie oryginalnych danych.\n",
    "\n",
    "<img src=\"Images/img_18.jpg\">\n",
    "\n",
    "Jako wynik otrzymaliśmy DataFrame o tym samym indeksie i kolumnach, co początkowy zbiór treningowy, ale wszystkie usunięte za pomocą \"SelectKBest\" kolumny są wypełnione zerami. \n",
    "\n",
    "Teraz możemy wybrać tylko te kolumny, dla których wartości są różne od zera (variance != 0):\n",
    "\n",
    "<img src=\"Images/img_19.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularyzacja L1\n",
    "\n",
    "Metody jednowymiarowe (univariate feature selection - jw) uwzględniają tylko jedną cechę naraz podczas podejmowania decyzji. Zamiast tego możemy dokonać wyboru przy użyciu wszystkich cech, włączając je do modelu liniowego poprzez zastosowanie **regularyzacji L1**. W przeciwieństwie do regularyzacji L2 ( **grzbietowa** ), która oblicza kwadrat współczynników dla poszczególnych cech, regularyzacja L1 (zwana również **_Lasso_** ) oblicza wartość bezwzględną tych współczynników.\n",
    "\n",
    "Wraz ze wzrostem \"siły\" regularyzacji, cechy które są mniej ważne z punktu widzenia zmiennej przewidywanej, są ustawiane na 0. Pozwala to dokonać wyboru cech poprzez dostosowanie parametru regularyzacji. Parametr ten możemy wybrać w taki sposób, aby jakość, dla cech które wybierzemy dla naszego modelu, była jak największa lub możemy wcześniej podjąć decyzje ile ostatecznie cech (kolumn) chcemy zachować.\n",
    "\n",
    "Chcąc dokonać klasyfikacji z użyciem regresji możemy skorzystać z metod pakietu Scikit-Learn i są to **sklearn.linear_model.Lasso** lub **sklearn.linear_model.Logisticregression**. Obu tych metod możemy użyć wraz z metodą **sklearn.feature_selection.SelectFromModel** , która służy właśnie do wyboru cech (kolumn), dla których wartość współczynnika regularyzacji jest różna od zera. W przeciwnym wypadku, kod przypomina ten dla metod jednowymiarowych.\n",
    "\n",
    "<img src=\"Images/img_20.jpg\">\n",
    "\n",
    "Podobnie, jak w przypadku metod jednowymiarowych, otrzymaliśmy tablicę wartości cech, które zostały zachowane i ponownie musimy dokonać konwersji do DataFrame, gdzie oprócz wartości będziemy mieli również nazwy cech (kolumn).\n",
    "\n",
    "<img src=\"Images/img_21.jpg\">\n",
    "\n",
    "W powyższym przykładzie zastosowanie parametru C = 1 powoduje, że odrzucamy kolumnę _time_since_last_project_ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PODSUMOWANIE**\n",
    "\n",
    "Ogólnie, metoda wyboru cech z użyciem regularyzacji L1 jest lepsza, aniżeli metody jednowymiarowe, ale potrafi być ona bardzo wolna, gdy posiadamy zbiór danych o dużej liczbie cech. Metody jednowymiarowe będą znacznie szybsze w przypadku dużych zbiorów danych, ale modele utworzone za ich pomocą nie są z kolei tak wydajne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
