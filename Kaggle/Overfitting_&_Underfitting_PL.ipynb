{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pojęcia\n",
    "\n",
    "**Cecha** - dowolne dane wejściowe modelu (wiek, wzrost, waga etc.), inaczej: kolumna tabeli.\n",
    "\n",
    "**Obserwacja** - pojedynczy przypadek opisany za pomocą wszystkich cech, inaczej: wiersz tabeli (dane opisane za pomocą kolejnych kolumn tabeli).\n",
    "\n",
    "**Regularyzacja** - proces polegający na zmnijeszeniu juz zwiększeniu stopnia złożoności modelu (czyli na zmianie liczby cech za pomocą, których będziemy trenować nasz model). Regularyzacja pozwala na zmniejszenie prawdopodobieństwa wystąpienia *overfittingu* lub *underfittingu*.\n",
    "\n",
    "**Ekstrakcja** - proces polegający na wyodrębnianiu nowych cech na podstawie posiadanych danych, które to później posłużą nam do wytrenowania modelu.\n",
    "\n",
    "**Zbiór treningowy** - cześć danych przeznaczonych do trenowania (uczenia) modelu.\n",
    "\n",
    "**Zbiór walidacyjny** - część danych wyodrębniona ze zbioru treningowego i służąca do oceny jakości modeli i wyboru najlepszego z nich. Podziału na zbiór “treningowy właściwy” i zbiór walidacyjny dokonuje się po preprocessingu zbioru treningowego (zbiór walidacyjny, który wyodrębnimy za pomocą *train_test_split* będzie już przetworzony). Zamiast dokonywać podziału ręcznie za pomocą metody *train_test_split* właśnie można użyć *walidacji krzyżowej* (daje lepsze wyniki).\n",
    "\n",
    "**Zbiór testowy** - część danych służąca do końcowej oceny wybranego modelu (wyodrębniona na samym początku, jeszcze przed preprocessingiem danych zatem nasz model tych danych nie zna). Do przetworzenia zbioru testowego do postaci takiej, jak ma zbiór treningowy (usunięcie braków danych, wyodrębnienie cech, kodowanie itp.) zazwyczaj używa się potoków (pipelines), ale też można to zrobić “na piechotę”.\n",
    "\n",
    "\n",
    "## Ocena jakości modelu\n",
    "\n",
    "Po wyuczeniu modelu nie wystarcza nam sama nadzieja na skuteczne przewidywanie przez model wyników dla nowych danych. Trzeba ocenić wydajność (skuteczność, jakość) modelu i w razie potrzeby dostroić go do swoich potrzeb.\n",
    "\n",
    "Jedynym sposobem sprawdzenia, jak dobrze model generalizuje (przewiduje) wyniki jest wypróbowanie go na nowych danych. Dokonuje się tego przez podział danych na dwa zestawy: **zbiór treningowy** (ang. training set) i **zbiór testowy** (ang. test set). Zgodnie z tymi nazwami, model trenujemy za pomocą zbioru uczącego, a sprawdzamy przy użyciu zbioru testowego. Współczynnik błędu uzyskiwany dla nowych przykładów nosi nazwę **błędu generalizacji** (błędu uogólniania), a dzięki zbiorowi testowemu możemy oszacować jego wartość. Parametr ten mówi nam również, jak dobrze model będzie się spisywał wobec nieznanych danych.\n",
    "\n",
    "Zazwyczaj na zbiór uczący składa się 80% danych, a pozostałe 20% przechowujemy w celu testowania. Zatem ocena modelu nie jest wcale taka trudna: wystarczy użyć zbioru testowego. \n",
    "\n",
    "Załóżmy teraz, że wahamy się przy wyborze jednego z dwóch modeli (np. pomiędzy wyborem modelu liniowego a wielomianowego). Jednym z rozwiązań jest wyuczenie obydwu modeli i sprawdzenie, jak sobie radzą z uogólnianiem wobec zbioru testowego. \n",
    "\n",
    "Przyjmijmy teraz, że model liniowy radzi sobie lepiej z uogólnianiem, ale chcemy wprowadzić *regularyzację* w celu uniknięcia przetrenowania. Pojawia się więc pytanie, w jaki sposób dobrać wartość **hiperparametrów regularyzacji**?\n",
    "Możemy np. wytrenować 100 różnych modeli, z których każdy będzie miał inną wartość tych hiperparametrów. Załóżmy, że znajdziemy optymalną wartość hiperparametrów, dającą model o najniższym błędzie generalizacji (np. rzędu 5%). Wprowadzamy zatem ten model do środowiska produkcyjnego, ale niestety, dla nowych danych sprawuje się on poniżej oczekiwań i generuje 15% błędów. Co się właściwie stało?\n",
    "\n",
    "Problem polega na tym, że wielokrotnie zmierzyliśmy błąd uogólniania wobec zbioru testowego i dostosowaliśmy go do tych danych! Oznacza to, że teraz prawdopodobnie model ten nie będzie sobie radził zbyt dobrze z nowymi próbkami...\n",
    "\n",
    "Powszechnie stosowanym rozwiązaniem tego problemu jest odłożenie jeszcze jednego (trzeciego) zbioru danych, zwanego **zbiorem walidacyjnym** (ang. validation set).\n",
    "\n",
    "Cały proces będzie teraz wyglądał następująco: \n",
    "- trenujemy wiele modeli mających różne wartości hiperparametrów za pomocą zbioru uczącego, \n",
    "- dobieramy model i hiperparametry najlepiej sprawujące się wobec zbioru walidacyjnego, a gdy uzyskiwane wyniki będą nas zadowalać, \n",
    "- przeprowadzamy ostatni sprawdzian wobec zbioru testowego, aby oszacować wartość błędu uogólniania.\n",
    "\n",
    "W sytuacji, gdy zbiór danych, na którym chcemy wytrenować model jest niewielki wyodrębnienie z niego zbioru walidacyjnego (a wcześniej również testowego) dodatkowo go zmniejszy. Prowadzić to może do uzyskania modelu o niskiej jakości (mało próbek do nauki). W celu uniknięcia „zużywania” zbyt dużej ilości danych uczących na zbiór walidacyjny, możemy skorzystać z techniki zwanej **walidacją krzyżową** (sprawdzian krzyżowy, ang. cross-validation): zbiór uczący zostaje rozdzielony na wzajemnie uzupełniające się podzbiory; każdy model jest uczony za pomocą różnych kombinacji tych podzbiorów i oceniany przy użyciu pozostałych, nieużytych podzestawów.\n",
    "\n",
    "Po dobraniu rodzaju modelu i hiperparametrów ostateczny model zostaje wytrenowany wobec pełnego zbioru uczącego, a błąd uogólniania określamy przy użyciu zbioru testowego.\n",
    "\n",
    "## Dwa główne problemu ML\n",
    "\n",
    "Typowym problemem uczenia maszynowego jest **overfitting** (nadmierne dopasowanie) - wygenerowanie modelu, który doskonale sprawdza się na treningowym zbiorze danych, ale generuje słabe wyniki w przypadku nowych danych. Przyczyną takiego stanu rzeczy może być tzw. *zaszumienie danych* lub zbyt mały zbiór treningowy.\n",
    "\n",
    "Sytuacją odwrotną jest **underfitting** (zbyt słabe dopasowanie) - wygenerowanie modelu, który daje kiepskie wyniki zarówno na nowych danych, jak i na treningowym zbiorze danych. Gdy dochodzi do takiej sytuacji, zwykle należy bardziej dopracować model lub znaleźć inny (lepszy).\n",
    "\n",
    "<img src=\"Images/img_78.jpg\">\n",
    "\n",
    "### Overfitting\n",
    "\n",
    "Overfitting (nadmierne dopasowanie, przeuczenie, przetrenowanie) - zjawisko, do którego dochodzi kiedy model, który wytrenowaliśmy radzi sobie bardzo dobrze podczas klasyfikacji na zbiorze treningowym i walidacyjnym, ale nie radzi sobie dobrze z klasyfikacją nowych obiektów. Inaczej, wartość błędu uczenia jest niewielka, ale błąd uogólniania jest duży, tzn. model rzadko się myli wobec zbioru uczącego, ale często wobec nowych danych (wobec zbioru testowego).\n",
    "\n",
    "Zwykle algorytm uczący jest wytrenowany na zbiorze treningowym (uczącym), dla którego znane są właściwe wyniki. Zakłada się, że po nauczeniu można zastosować ten algorytm do przewidywania wyników także dla innych przypadków, czyli algorytm w procesie uczenia znajdzie prawidłowości w zbiorze treningowym (uczącym) dla wszelkich podobnych obserwacji. Jednakże, w sytuacji gdy uczenie jest zbyt długie lub gdy przypadków uczących jest zbyt mało, uczeń może “wymyślić” prawidłowości, które w rzeczywistości nie mają sensu, a są efektem przypadkowych błędów w danych uczących. W wyniku przeuczenia jakość algorytmu dla danych uczących wzrasta, ale w przypadku zastosowania go do nieznanych danych jakość ta spada (podejmuje on błędne decyzje).\n",
    "\n",
    "W celu uniknięcia nadmiernego dopasowania (przeuczenia) konieczne jest zastosowanie dodatkowych środków (np. zbiorów testowych, walidacji krzyżowej, bootstrapu), które pozwolą stwierdzić, w którym momencie dalsze uczenie zaczyna prowadzić do pogorszenia modelu (spadku jakości algorytmu) - jest to tzw. optymalizacja modelu.\n",
    "\n",
    "Rozwiązania pozwalające zmniejszyć ryzyko przetrenowania:\n",
    "- uproszczenie modelu poprzez wybór modelu zawierającego mniej parametrów (np. bierzemy model liniowy zamiast modelu wielomianowego)\n",
    "- zmniejszenie liczby atrybutów w danych uczących lub ograniczenie modelu (regularyzacja)\n",
    "- uzyskanie większej ilości danych uczących (więcej wierszy)\n",
    "- zmniejszenie zaszumienia danych uczących (np. poprzez usunięcie błędnych danych lub elementów odstających)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
